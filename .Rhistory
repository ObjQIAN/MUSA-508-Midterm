<<<<<<< Updated upstream
group_by(DIST_NAME) %>%
summarize(meanPrediction = mean(sale_price.Predict),
meanPrice = mean(sale_price)) %>%
kable() %>%
kable_styling()
reg.nhood <- lm(sale_price ~ ., data = as.data.frame(philly.training) %>%
dplyr::select(zip_code, sale_price,
total_livable_area, crimes.Buffer))
philly.test.nhood <-
philly.test %>%
mutate(Regression = "Neighborhood Effects",
sale_price.Predict = predict(reg.nhood, philly.test),
sale_price.Error = sale_price.Predict- sale_price,
sale_price.AbsError = abs(sale_price.Predict- sale_price),
sale_price.APE = (abs(sale_price.Predict- sale_price)) / sale_price)%>%
filter(sale_price < 5000000)
bothRegressions <-
rbind(
dplyr::select(philly.test, starts_with("sale_price"), Regression, DIST_NAME) %>%
mutate(lagPriceError = lag.listw(spatialWeights.test, sale_price.Error)),
dplyr::select(philly.test.nhood, starts_with("sale_price"), Regression, DIST_NAME) %>%
mutate(lagPriceError = lag.listw(spatialWeights.test, sale_price.Error)))
st_drop_geometry(bothRegressions) %>%
gather(Variable, Value, -Regression, -DIST_NAME) %>%
filter(Variable == "sale_price.AbsError" | Variable == "sale_price.APE") %>%
group_by(Regression, Variable) %>%
summarize(meanValue = mean(Value, na.rm = T)) %>%
spread(Variable, meanValue) %>%
kable()
bothRegressions %>%
dplyr::select(sale_price.Predict, sale_price, Regression) %>%
ggplot(aes(sale_price, sale_price.Predict)) +
geom_point() +
stat_smooth(aes(sale_price, sale_price.Predict),
method = "lm", se = FALSE, size = 1, colour="#FA7800") +
stat_smooth(aes(sale_price.Predict, sale_price),
method = "lm", se = FALSE, size = 1, colour="#25CB10") +
facet_wrap(~Regression) +
labs(title="Predicted sale price as a function of observed price",
subtitle="Orange line represents a perfect prediction; Green line represents prediction") +
plotTheme()
st_drop_geometry(bothRegressions) %>%
group_by(Regression, DIST_NAME) %>%
summarize(mean.MAPE = mean(sale_price.APE, na.rm = T)) %>%
ungroup() %>%
left_join(district, by = c("DIST_NAME" = "DIST_NAME")) %>%
st_sf() %>%
ggplot() +
geom_sf(aes(fill = mean.MAPE)) +
geom_sf(data = bothRegressions, colour = "black", size = .1) +
facet_wrap(~Regression) +
scale_fill_gradient(low = palette5[1], high = palette5[5],
name = "MAPE") +
labs(title = "Mean test set MAPE by neighborhood") +
mapTheme()
tracts20 <-
get_acs(geography = "tract", variables = c("B25026_001E","B02001_002E","B19013_001E"),
year=2020, state=42, county=101, geometry=TRUE, output="wide") %>%
st_transform('ESRI:102729') %>%
rename(TotalPop = B25026_001E,
NumberWhites =B02001_002E,
Median_Income = B19013_001E) %>%
mutate(percentWhite = NumberWhites / TotalPop,
raceContext = ifelse(percentWhite > .5, "Majority White", "Majority Non-White"),
incomeContext = ifelse(Median_Income > 32322, "High Income", "Low Income"))
grid.arrange(ncol = 2,
ggplot() + geom_sf(data = na.omit(tracts20), aes(fill = raceContext)) +
scale_fill_manual(values = c("#25CB10", "#FA7800"), name="Race Context") +
labs(title = "Race Context") +
mapTheme() + theme(legend.position="bottom"),
ggplot() + geom_sf(data = na.omit(tracts20), aes(fill = incomeContext)) +
scale_fill_manual(values = c("#25CB10", "#FA7800"), name="Income Context") +
labs(title = "Income Context") +
mapTheme() +
theme(legend.position="bottom"))
st_join(bothRegressions, tracts20) %>%
group_by(Regression, raceContext) %>%
summarize(mean.MAPE = scales::percent(mean(sale_price.APE, na.rm = T))) %>%
st_drop_geometry() %>%
spread(raceContext, mean.MAPE) %>%
kable(caption = "Test set MAPE by neighborhood racial context")
bothRegressions %>%
dplyr::select(sale_price.Predict, sale_price, Regression) %>%
ggplot(aes(sale_price, sale_price.Predict)) +
geom_point() +
stat_smooth(aes(sale_price, sale_price.Predict),
method = "lm", se = FALSE, size = 1, colour="#FA7800") +
stat_smooth(aes(sale_price.Predict, sale_price),
method = "lm", se = FALSE, size = 1, colour="#25CB10") +
labs(title="Predicted sale price as a function of observed price",
subtitle="Orange line represents a perfect prediction; Green line represents prediction") +
plotTheme()
assign_test <- predict(reg.training , newdata=to_predict)
to_predict<-  to_predict %>%
dplyr::select(musaID) %>%
mutate(team)
to_predict<-  to_predict %>%
dplyr::select(musaID) %>%
mutate('team')
to_predict<-  to_predict %>%
dplyr::select(musaID) %>%
mutate('team' = 'a team')
assign_test <- predict(reg.training , newdata=to_predict)
to_predict <-
to_train %>%
dplyr::filter(toPredict == 'CHALLENGE') #Select data for later prediction
to_predict$predict <- assign_test
to_predict<-  to_predict %>%
dplyr::select(musaID,predict) %>%
mutate('team' = 'a team')
View(to_predict)
to_predict<-  to_predict %>%
dplyr::select(musaID,predict) %>%
mutate('team' = 'a team') %>%
st_drop_geometry()
View(to_predict)
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(tidycensus)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(broom)
library(tufte)
library(rmarkdown)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
# functions and data directory
root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
acs_vars <- c("B01001_001E", # ACS total Pop estimate
"B25002_001E", # Estimate of total housing units
"B25002_003E", # Number of vacant housing units
"B19013_001E", # Median HH Income ($)
"B02001_002E", # People describing themselves as "white alone"
"B06009_006E") # Total graduate or professional degree
acsTractsPHL.2020 <- get_acs(geography = "tract",
year = 2020,
variables = acs_vars,
geometry = TRUE,
state = "PA",
county = "Philadelphia",
output = "wide") %>%
st_transform('ESRI:102729')
# import planning district and housing data
district <-
st_read("https://raw.githubusercontent.com/ObjQIAN/MUSA-508-Midterm/main/data/Planning_Districts.geojson") %>%
dplyr::select(DIST_NAME,ABBREV) %>% #Select data for later prediction
st_transform('ESRI:102729')
nhoods_0 <-
st_read("https://raw.githubusercontent.com/ObjQIAN/MUSA-508-Midterm/main/data/studentData.geojson") %>%
st_transform('ESRI:102729')
nhoods <- st_join(nhoods_0, district)
to_train <- nhoods
#??
#Philadelphia <-
# read.csv(file.path(root.dir,"/Chapter3_4/phillyHousePriceData_clean.csv"))
# Load crime data
philadelphiCrimes <- read.csv('https://raw.githubusercontent.com/ObjQIAN/MUSA-508-Midterm/main/data/Philadelphia_crime.csv')
# Create sf and select related crimes
crime_codes_set <- c("Weapon Violations", "Thefts", "Robbery Firearm", 'Vandalism/Criminal Mischief', 'Homicide - Criminal ','Homicide - Criminal', 'Burglary Residential')
philadelphiCrimes.sf <-
philadelphiCrimes %>%
filter(text_general_code %in% crime_codes_set,
lat > -1) %>%
dplyr::select(lat, lng) %>%
na.omit() %>%
st_as_sf(coords = c( "lng","lat"), crs = "EPSG:4326") %>%
st_transform('ESRI:102729') %>%
distinct()
# Load 311 data and select related variables
call311_codes_set <- c('Illegal Dumping','Abandoned Vehicle','Street Defect','Graffiti Removal','Dangerous Building Complaint','Homeless Encampment Request','Abandoned Bike','Opioid Response Unit')
philadelphia311.sf <- read.csv('https://phl.carto.com/api/v2/sql?filename=public_cases_fc&format=csv&skipfields=cartodb_id,the_geom,the_geom_webmercator&q=SELECT%20*%20FROM%20public_cases_fc%20WHERE%20requested_datetime%20%3E=%20%272022-01-01%27%20AND%20requested_datetime%20%3C%20%272023-01-01%27') %>%
filter(service_name %in% call311_codes_set,
lat > -1) %>%
dplyr::select(lat, lon) %>%
na.omit() %>%
st_as_sf(coords = c("lon", "lat"), crs = 4326, agr = "constant") %>%
st_transform('ESRI:102729')
# ggplot, reorder
# Mapping data
ggplot() +
geom_sf(data = district, fill = "grey40") +
geom_sf(data = to_train, aes(colour = q5(sale_price)),
show.legend = "point", size = .35) +
scale_colour_manual(values = palette5,
labels=qBr(to_train,"sale_price"),
name="Quintile\nBreaks") +
labs(title="House Sale Price, Philadelphia") +
mapTheme()
# Counts of crime per buffer of house sale
to_train$crimes.Buffer <- to_train %>%
st_buffer(660) %>%
aggregate(mutate(philadelphiCrimes.sf, counter = 1),., sum) %>%
pull(counter)
## Nearest Neighbor Feature
to_train <-
to_train %>%
mutate(
crime_nn1 = nn_function(st_coordinates(to_train),
st_coordinates(philadelphiCrimes.sf), k = 1),
crime_nn2 = nn_function(st_coordinates(to_train),
st_coordinates(philadelphiCrimes.sf), k = 2),
crime_nn3 = nn_function(st_coordinates(to_train),
st_coordinates(philadelphiCrimes.sf), k = 3),
crime_nn4 = nn_function(st_coordinates(to_train),
st_coordinates(philadelphiCrimes.sf), k = 4),
crime_nn5 = nn_function(st_coordinates(to_train),
st_coordinates(philadelphiCrimes.sf), k = 5))
## Plot assault density
ggplot() + geom_sf(data = acsTractsPHL.2020, fill = "grey40") +
stat_density2d(data = data.frame(st_coordinates(philadelphiCrimes.sf)),
aes(X, Y, fill = ..level.., alpha = ..level..),
size = 0.01, bins = 40, geom = 'polygon') +
scale_fill_gradient(low = "#25CB10", high = "#FA7800", name = "Density") +
scale_alpha(range = c(0.00, 0.35), guide = "none") +
labs(title = "Density of WA, PHL") +
mapTheme()
# Counts of 311 per buffer of house sale
to_train$philly311.Buffer <- to_train %>%
st_buffer(660) %>%
aggregate(mutate(philadelphia311.sf, counter = 1),., sum) %>%
pull(counter)
## Nearest Neighbor Feature
to_train <-
to_train %>%
mutate(
p311_nn1 = nn_function(st_coordinates(to_train),
st_coordinates(philadelphia311.sf), k = 1),
p311_nn2 = nn_function(st_coordinates(to_train),
st_coordinates(philadelphia311.sf), k = 2),
p311_nn3 = nn_function(st_coordinates(to_train),
st_coordinates(philadelphia311.sf), k = 3),
p311_nn4 = nn_function(st_coordinates(to_train),
st_coordinates(philadelphia311.sf), k = 4),
p311_nn5 = nn_function(st_coordinates(to_train),
st_coordinates(philadelphia311.sf), k = 5))
## Plot 311 density-????
ggplot() + geom_sf(data = acsTractsPHL.2020, fill = "grey40") +
stat_density2d(data = data.frame(st_coordinates(philadelphia311.sf)),
aes(X, Y, fill = ..level.., alpha = ..level..),
size = 0.01, bins = 40, geom = 'polygon') +
scale_fill_gradient(low = "#25CB10", high = "#FA7800", name = "Density") +
scale_alpha(range = c(0.1, 0.35), guide = "none") +
labs(title = "Density of 311, PHL") +
mapTheme()
## Crime cor
to_train %>%
st_drop_geometry() %>%
dplyr::select(sale_price, starts_with("crime_")) %>%
filter(sale_price <= 1000000) %>%
gather(Variable, Value, -sale_price) %>%
ggplot(aes(Value, sale_price)) +
geom_point(size = .5) +
geom_smooth(data = . %>% filter(sale_price > 0), method = "lm", se=F, colour = "#FA7800") +
facet_wrap(~Variable, nrow = 1, scales = "free") +
labs(title = "Price as a function of continuous variables") +
plotTheme()
# the result above is too similar, So we calculate and compare the R^2 to choose which crime data to use.
# The result shows that crime_nn3 is the best one.
to_train <- to_train %>%
mutate(Age = 2022 - year_built) #%>%
# dplyr::filter(toPredict == 'MODELLING') #Select data for later prediction
to_predict <-
to_train %>%
dplyr::filter(toPredict == 'CHALLENGE') #Select data for later prediction
philly_sub_200k <- st_drop_geometry(to_train) %>%
filter(sale_price <= 2000000, total_livable_area < 10000, total_livable_area > 0,toPredict == 'MODELLING')
Crime1Reg <- lm(sale_price ~ crime_nn1, data = philly_sub_200k)
summary(Crime1Reg)
Crime2Reg <- lm(sale_price ~ crime_nn2, data = philly_sub_200k)
summary(Crime2Reg)
Crime3Reg <- lm(sale_price ~ crime_nn3, data = philly_sub_200k)
summary(Crime3Reg)
Crime4Reg <- lm(sale_price ~ crime_nn4, data = philly_sub_200k)
summary(Crime4Reg)
Crime5Reg <- lm(sale_price ~ crime_nn5, data = philly_sub_200k)
summary(Crime5Reg)
## Home Features cor
st_drop_geometry(to_train) %>%
dplyr::select(sale_price, total_livable_area, Age, crime_nn5,
depth, frontage, off_street_open, philly311.Buffer,garage_spaces) %>%
filter(sale_price <= 1000000, Age < 500, total_livable_area <10000, frontage < 500) %>%
gather(Variable, Value, -sale_price) %>%
ggplot(aes(Value, sale_price)) +
geom_point(size = .5) +
geom_smooth(data = . %>% filter(sale_price >0), method = "lm", se=F, colour = "#FA7800") +
facet_wrap(~Variable, ncol = 3, scales = "free") +
labs(title = "Price as a function of continuous variables") +
plotTheme()
#这里的代码我不知道要怎么合并一下好
to_train %>%
dplyr::select(sale_price, exterior_condition) %>%
mutate(exterior_condition = as.factor(exterior_condition)) %>%
filter(sale_price <= 1000000) %>%
group_by(exterior_condition) %>%
summarize(avg_sale_price = mean(sale_price)) %>%
ggplot(aes(x = exterior_condition, y = avg_sale_price)) +
geom_bar(stat = "identity") +
labs(
title = "Average Sale Price by Exterior Condition",
y = "Average Sale Price"
) +
plotTheme() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
to_train %>%
dplyr::select(sale_price, fireplaces) %>%
mutate(fireplaces = as.factor(fireplaces)) %>%
filter(sale_price <= 1000000) %>%
filter(!is.na(fireplaces)) %>%
group_by(fireplaces) %>%
summarize(avg_sale_price = mean(sale_price)) %>%
ggplot(aes(x = fireplaces, y = avg_sale_price)) +
geom_bar(stat = "identity") +
labs(
title = "Average Sale Price by Fireplaces",
y = "Average Sale Price"
) +
plotTheme() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
to_train %>%
dplyr::select(sale_price, interior_condition) %>%
mutate(interior_condition = as.factor(interior_condition)) %>%
filter(sale_price <= 1000000) %>%
filter(!is.na(interior_condition)) %>%
group_by(interior_condition) %>%
summarize(avg_sale_price = mean(sale_price)) %>%
ggplot(aes(x = interior_condition, y = avg_sale_price)) +
geom_bar(stat = "identity") +
labs(
title = "Average Sale Price by Interior Condition",
y = "Average Sale Price"
) +
plotTheme() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
to_train %>%
dplyr::select(sale_price, number_of_bathrooms) %>%
mutate(number_of_bathrooms = as.factor(number_of_bathrooms)) %>%
filter(sale_price <= 1000000) %>%
filter(!is.na(number_of_bathrooms)) %>%
group_by(number_of_bathrooms) %>%
summarize(avg_sale_price = mean(sale_price)) %>%
ggplot(aes(x = number_of_bathrooms, y = avg_sale_price)) +
geom_bar(stat = "identity") +
labs(
title = "Average Sale Price by Number of Bathrooms",
y = "Average Sale Price"
) +
plotTheme() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
to_train %>%
dplyr::select(sale_price, number_of_bedrooms) %>%
mutate(number_of_bedrooms = as.factor(number_of_bedrooms)) %>%
filter(sale_price <= 1000000) %>%
filter(!is.na(number_of_bedrooms)) %>%
group_by(number_of_bedrooms) %>%
summarize(avg_sale_price = mean(sale_price)) %>%
ggplot(aes(x = number_of_bedrooms, y = avg_sale_price)) +
geom_bar(stat = "identity") +
labs(
title = "Average Sale Price by Number of Bedrooms",
y = "Average Sale Price"
) +
plotTheme() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
to_train %>%
dplyr::select(sale_price, number_stories) %>%
mutate(number_stories = as.factor(number_stories)) %>%
filter(sale_price <= 1000000) %>%
filter(!is.na(number_stories)) %>%
group_by(number_stories) %>%
summarize(avg_sale_price = mean(sale_price)) %>%
ggplot(aes(x = number_stories, y = avg_sale_price)) +
geom_bar(stat = "identity") +
labs(
title = "Average Sale Price by Number of Stories",
=======
>>>>>>> Stashed changes
y = "Average Sale Price"
) +
plotTheme() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# add reclassified data
to_train <- to_train %>%
mutate(
exterior_condition_re = case_when(
exterior_condition %in% 1:3 ~ 1,
exterior_condition %in% 4:5 ~ 2,
exterior_condition %in% 6:7 ~ 3
)
) %>%
mutate(
fireplaces_re = case_when(
fireplaces %in% 0:1 ~ 1,
fireplaces == 2     ~ 2,
fireplaces %in% 3:5 ~ 3
)
) %>%
mutate(
interior_condition_re = case_when(
interior_condition %in% 0:2 ~ 1,
interior_condition %in% 3:4 ~ 2,
interior_condition %in% 5:7 ~ 3
)
) %>%
mutate(
number_of_bathrooms_re = case_when(
number_of_bathrooms ==0      ~ 1,
number_of_bathrooms %in% 1:2 ~ 2,
number_of_bathrooms %in% 3:6 ~ 3
)
) %>%
mutate(
number_of_bedrooms_re = case_when(
number_of_bedrooms %in% 0:1 ~ 1,
number_of_bedrooms %in% 2:3 ~ 2,
number_of_bedrooms %in% 4:31 ~ 3
)
)%>%
mutate(
number_stories_re = case_when(
number_stories == 1     ~ 1,
number_stories == 2     ~ 2,
number_stories %in% 3:5 ~ 3
)
)
philly_sub_200k <- st_drop_geometry(to_train) %>%
filter(sale_price <= 2000000, total_livable_area < 10000, total_livable_area > 0)
numericVars <-
select_if(st_drop_geometry(to_train), is.numeric) %>% na.omit()
ggcorrplot(
round(cor(numericVars), 1),
p.mat = cor_pmat(numericVars),
colors = c("#25CB10", "white", "#FA7800"),
type="lower",
insig = "blank") +
labs(title = "Correlation across numeric variables")
#有无穷或遗漏值？
# yet another way to plot the correlation plot using the corrr library
#numericVars %>%
#  correlate() %>%
#  autoplot() +
#  geom_text(aes(label = round(r,digits=2)),size = 2)
ex_Reg <- lm(sale_price ~ exterior_condition, data = philly_sub_200k)
summary(ex_Reg)
in_Reg <- lm(sale_price ~ interior_condition, data = philly_sub_200k)
summary(in_Reg)
cor.test(philly_sub_200k$total_livable_area,
philly_sub_200k$sale_price,
method = "pearson")
livingReg <- lm(sale_price ~ total_livable_area, data = philly_sub_200k)
summary(livingReg)
ggscatter(philly_sub_200k,
x = "total_livable_area",
y = "sale_price",
add = "reg.line") +
stat_cor(aes(label = paste(..rr.label.., ..p.label.., sep = "~`,`~")), label.y = 2500000) +
stat_regline_equation(label.y = 2250000)
coefficients(livingReg)
new_total_livable_area = 4000
# "by hand"
-41433.9841  + 88.34939 * new_total_livable_area
# predict() function
predict(livingReg, newdata = data.frame(total_livable_area = 4000))
reg1 <- lm(sale_price ~ ., data = philly_sub_200k %>%
dplyr::select(sale_price, Age, total_livable_area, crime_nn3, philly311.Buffer,
geographic_ward,garage_spaces,
fireplaces, interior_condition,exterior_condition, number_of_bathrooms,
number_of_bedrooms, number_stories))
summary(reg1)
par(mfrow=c(2,2))
plot(reg1)
## Plot of marginal response
effect_plot(reg1, pred = total_livable_area, interval = TRUE, plot.points = TRUE)
## Plot coefficients
plot_summs(reg1, scale = TRUE)
## plot multiple model coeffs
plot_summs(reg1, livingReg)
inTrain <- createDataPartition(
y = paste(to_train$building_code_description, to_train$quality_grade),
p = .60, list = FALSE)
philly.training <- to_train[inTrain,]
philly.test <- to_train[-inTrain,]
reg.training <-
lm(sale_price ~ ., data = as.data.frame(philly.training) %>%
dplyr::select(sale_price, total_livable_area, crimes.Buffer))
philly.test <-
philly.test %>%
mutate(Regression = "Baseline Regression",
sale_price.Predict = predict(reg.training, philly.test),
sale_price.Error = sale_price.Predict - sale_price,
sale_price.AbsError = abs(sale_price.Predict - sale_price),
sale_price.APE = (abs(sale_price.Predict - sale_price)) / sale_price.Predict)%>%
filter(sale_price < 5000000)
<<<<<<< Updated upstream
# predict competition
assign_test <- predict(reg.training , newdata=to_predict)
to_predict$predict <- assign_test
to_predict<-  to_predict %>%
dplyr::select(musaID,predict) %>%
mutate('team' = 'a team') %>%
st_drop_geometry()
write.csv(to_predict,"mean_prediction.csv", row.names = FALSE)
=======
# Remove invalid predictions (Maybe need to do this before running the test)
philly.test <-  philly.test[!with(philly.test,is.na(sale_price.Predict)),]
coords <- st_coordinates(philly.test)
neighborList <- knn2nb(knearneigh(coords, 5))
spatialWeights <- nb2listw(neighborList, style="W")
philly.test$lagPrice <- lag.listw(spatialWeights, philly.test$sale_price)
coords.test <-  st_coordinates(philly.test)
neighborList.test <- knn2nb(knearneigh(coords.test, 5))
spatialWeights.test <- nb2listw(neighborList.test, style="W")
ggplot() +
geom_point(data = philly.test, aes(x = lagPrice, y = sale_price), size = 2) +
geom_smooth(data = philly.test, aes(x = lagPrice, y = sale_price), method = "lm", se = F, colour = "#FA7800") +
labs(title = "Price as a function of the spatial lag of price",
x = "Spatial Lag of Price (Mean price of 5 nearest neighbors)",
y = "Sale Price")
philly.test %>%
mutate(lagPriceError = lag.listw(spatialWeights.test, sale_price.Error)) %>%
ggplot()+
geom_point(aes(x =lagPriceError, y =sale_price.Error)) +
geom_smooth(aes(x = lagPriceError, y = sale_price.Error),method = "lm", se=F, colour = "#FA7800") +
labs(title = "Error as a function of the spatial lag of price",
x = "Spatial Lag of Error (Mean error of 5 nearest neighbors)", y = "Sale Price")
moranTest <- moran.mc(philly.test$sale_price.Error,
spatialWeights.test, nsim = 999)
ggplot(as.data.frame(moranTest$res[c(1:999)]), aes(moranTest$res[c(1:999)])) +
geom_histogram(binwidth = 0.01) +
geom_vline(aes(xintercept = moranTest$statistic), colour = "#FA7800",size=1) +
scale_x_continuous(limits = c(-1, 1)) +
labs(title="Observed and permuted Moran's I",
subtitle= "Observed Moran's I in orange",
x="Moran's I",
y="Count") +
plotTheme()
philly.test %>%
as.data.frame() %>%
# Tract is not a good factor here
group_by(zip_code) %>%
summarize(meanPrediction = mean(sale_price.Predict),
meanPrice = mean(sale_price)) %>%
kable() %>%
kable_styling()
reg.nhood <- lm(sale_price ~ ., data = as.data.frame(philly.training) %>%
dplyr::select(zip_code, sale_price,
total_livable_area, crimes.Buffer))
philly.test.nhood <-
philly.test %>%
mutate(Regression = "Neighborhood Effects",
sale_price.Predict = predict(reg.nhood, philly.test),
sale_price.Error = sale_price.Predict- sale_price,
sale_price.AbsError = abs(sale_price.Predict- sale_price),
sale_price.APE = (abs(sale_price.Predict- sale_price)) / sale_price)%>%
filter(sale_price < 5000000)
bothRegressions <-
rbind(
dplyr::select(philly.test, starts_with("sale_price"), Regression, zip_code) %>%
mutate(lagPriceError = lag.listw(spatialWeights.test, sale_price.Error)),
dplyr::select(philly.test.nhood, starts_with("sale_price"), Regression, zip_code) %>%
mutate(lagPriceError = lag.listw(spatialWeights.test, sale_price.Error)))
st_drop_geometry(bothRegressions) %>%
gather(Variable, Value, -Regression, -zip_code) %>%
filter(Variable == "sale_price.AbsError" | Variable == "sale_price.APE") %>%
group_by(Regression, Variable) %>%
summarize(meanValue = mean(Value, na.rm = T)) %>%
spread(Variable, meanValue) %>%
kable()
bothRegressions %>%
dplyr::select(sale_price.Predict, sale_price, Regression) %>%
ggplot(aes(sale_price, sale_price.Predict)) +
geom_point() +
stat_smooth(aes(sale_price, sale_price.Predict),
method = "lm", se = FALSE, size = 1, colour="#FA7800") +
stat_smooth(aes(sale_price.Predict, sale_price),
method = "lm", se = FALSE, size = 1, colour="#25CB10") +
facet_wrap(~Regression) +
labs(title="Predicted sale price as a function of observed price",
subtitle="Orange line represents a perfect prediction; Green line represents prediction") +
plotTheme()
st_drop_geometry(bothRegressions) %>%
group_by(Regression, zip_code) %>%
summarize(mean.MAPE = mean(sale_price.APE, na.rm = T)) %>%
ungroup() %>%
st_join(acsTractsPHL.2020) %>%
st_sf() %>%
ggplot() +
geom_sf(aes(fill = mean.MAPE)) +
geom_sf(data = bothRegressions, colour = "black", size = .1) +
facet_wrap(~Regression) +
scale_fill_gradient(low = palette5[1], high = palette5[5],
name = "MAPE") +
labs(title = "Mean test set MAPE by neighborhood") +
mapTheme()
st_drop_geometry(bothRegressions) %>%
group_by(Regression, zip_code) %>%
summarize(mean.MAPE = mean(sale_price.APE, na.rm = T)) %>%
ungroup() %>%
st_join(acsTractsPHL.2020) %>%
st_sf() %>%
ggplot() +
geom_sf(aes(fill = mean.MAPE)) +
geom_sf(data = bothRegressions, colour = "black", size = .1) +
facet_wrap(~Regression) +
scale_fill_gradient(low = palette5[1], high = palette5[5],
name = "MAPE") +
labs(title = "Mean test set MAPE by neighborhood") +
mapTheme()
tracts20 <-
get_acs(geography = "tract", variables = c("B25026_001E","B02001_002E","B19013_001E"),
year=2020, state=42, county=101, geometry=TRUE, output="wide") %>%
st_transform('ESRI:102729') %>%
rename(TotalPop = B25026_001E,
NumberWhites =B02001_002E,
Median_Income = B19013_001E) %>%
mutate(percentWhite = NumberWhites / TotalPop,
raceContext = ifelse(percentWhite > .5, "Majority White", "Majority Non-White"),
incomeContext = ifelse(Median_Income > 32322, "High Income", "Low Income"))
grid.arrange(ncol = 2,
ggplot() + geom_sf(data = na.omit(tracts20), aes(fill = raceContext)) +
scale_fill_manual(values = c("#25CB10", "#FA7800"), name="Race Context") +
labs(title = "Race Context") +
mapTheme() + theme(legend.position="bottom"),
ggplot() + geom_sf(data = na.omit(tracts20), aes(fill = incomeContext)) +
scale_fill_manual(values = c("#25CB10", "#FA7800"), name="Income Context") +
labs(title = "Income Context") +
mapTheme() +
theme(legend.position="bottom"))
st_join(bothRegressions, tracts20) %>%
group_by(Regression, raceContext) %>%
summarize(mean.MAPE = scales::percent(mean(sale_price.APE, na.rm = T))) %>%
st_drop_geometry() %>%
spread(raceContext, mean.MAPE) %>%
kable(caption = "Test set MAPE by neighborhood racial context")
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(tidycensus)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(broom)
library(tufte)
library(rmarkdown)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
# functions and data directory
root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
# import planning district and housing data
district <-
st_read("https://raw.githubusercontent.com/ObjQIAN/MUSA-508-Midterm/main/data/Planning_Districts.geojson") %>%
dplyr::select(DIST_NAME,ABBREV) %>% #Select data for later prediction
st_transform('ESRI:102729')
nhoods_0 <-
st_read("https://raw.githubusercontent.com/ObjQIAN/MUSA-508-Midterm/main/data/studentData.geojson") %>%
st_transform('ESRI:102729')
nhoods <- st_join(nhoods_0, district)
to_predict <-
nhoods %>%
dplyr::filter(toPredict == 'CHALLENGE') #Select data for later prediction
to_train <-
nhoods %>%
dplyr::filter(toPredict == 'MODELLING') #Select data for training Model
# ggplot, reorder
# Mapping data
ggplot() +
geom_sf(data = district, fill = "grey40") +
geom_sf(data = to_train, aes(colour = q5(sale_price)),
show.legend = "point", size = .35) +
scale_colour_manual(values = palette5,
labels=qBr(to_train,"sale_price"),
name="Quintile\nBreaks") +
labs(title="House Sale Price, Philadelphia") +
mapTheme()
census_api_key("5c7b1ebb206012789759942ddf1acbb882f937ad", overwrite = TRUE)
acs_vars <- c("B01001_001E", # ACS total Pop estimate
"B25002_001E", # Estimate of total housing units
"B25002_003E", # Number of vacant housing units
"B19013_001E", # Median HH Income ($)
"B02001_002E", # People describing themselves as "white alone"
"B06009_006E") # Total graduate or professional degree
acsTractsPHL.2020 <-
get_acs(geography = "tract",
variables = c("B25026_001E","B02001_002E",
"B25002_003E", "B25002_001E",
"B15001_050E","B15001_009E",
"B19013_001E","B25058_001E",
"B06012_002E"),
year=2020, state=42, county=101,
geometry=TRUE, output="wide") %>%
st_transform('ESRI:102729') %>%
rename(TotalPop = B25026_001E,
Whites = B02001_002E,
VacantHU = B25002_003E,
TotalHU = B25002_001E,
FemaleBachelors = B15001_050E,
MaleBachelors = B15001_009E,
MedHHInc = B19013_001E,
MedRent = B25058_001E,
TotalPoverty = B06012_002E) %>%
dplyr::select(-NAME, -starts_with("B")) %>%
mutate(pctWhite = ifelse(TotalPop > 0, Whites / TotalPop,0),
pctVacant = ifelse(TotalPop > 0, VacantHU / TotalPop,0),
pctBachelors = ifelse(TotalPop > 0, ((FemaleBachelors + MaleBachelors) / TotalPop),0),
pctPoverty = ifelse(TotalPop > 0, TotalPoverty / TotalPop, 0),
year = "2020") %>%
dplyr::select(-Whites, -FemaleBachelors, -MaleBachelors, -TotalPoverty)
acsTractsPHL.2020 <- get_acs(geography = "tract",
year = 2020,
variables = acs_vars,
geometry = TRUE,
state = "PA",
county = "Philadelphia",
output = "wide") %>%
st_transform('ESRI:102729')
acsTractsPHL.2020 <-
get_acs(geography = "tract",
variables = c("B25026_001E","B02001_002E",
"B25002_003E", "B25002_001E",
"B15001_050E","B15001_009E",
"B19013_001E","B25058_001E",
"B06012_002E"),
year=2020, state=42, county=101,
geometry=TRUE, output="wide") %>%
st_transform('ESRI:102729') %>%
rename(TotalPop = B25026_001E,
Whites = B02001_002E,
VacantHU = B25002_003E,
TotalHU = B25002_001E,
FemaleBachelors = B15001_050E,
MaleBachelors = B15001_009E,
MedHHInc = B19013_001E,
MedRent = B25058_001E,
TotalPoverty = B06012_002E) %>%
dplyr::select(-NAME, -starts_with("B")) %>%
mutate(pctWhite = ifelse(TotalPop > 0, Whites / TotalPop,0),
pctVacant = ifelse(TotalPop > 0, VacantHU / TotalPop,0),
pctBachelors = ifelse(TotalPop > 0, ((FemaleBachelors + MaleBachelors) / TotalPop),0),
pctPoverty = ifelse(TotalPop > 0, TotalPoverty / TotalPop, 0),
year = "2020") %>%
dplyr::select(-Whites, -FemaleBachelors, -MaleBachelors, -TotalPoverty)
#??
#Philadelphia <-
# read.csv(file.path(root.dir,"/Chapter3_4/phillyHousePriceData_clean.csv"))
# Load crime data
philadelphiCrimes <- read.csv('https://raw.githubusercontent.com/ObjQIAN/MUSA-508-Midterm/main/data/Philadelphia_crime.csv')
# Create sf and select related crimes
crime_codes_set <- c("Weapon Violations", "Thefts", "Robbery Firearm", 'Vandalism/Criminal Mischief', 'Homicide - Criminal ','Homicide - Criminal', 'Burglary Residential')
philadelphiCrimes.sf <-
philadelphiCrimes %>%
filter(text_general_code %in% crime_codes_set,
lat > -1) %>%
dplyr::select(lat, lng) %>%
na.omit() %>%
st_as_sf(coords = c( "lng","lat"), crs = "EPSG:4326") %>%
st_transform('ESRI:102729') %>%
distinct()
# Load 311 data and select related variables
call311_codes_set <- c('Illegal Dumping','Abandoned Vehicle','Street Defect','Graffiti Removal','Dangerous Building Complaint','Homeless Encampment Request','Abandoned Bike','Opioid Response Unit')
philadelphia311.sf <- read.csv('https://phl.carto.com/api/v2/sql?filename=public_cases_fc&format=csv&skipfields=cartodb_id,the_geom,the_geom_webmercator&q=SELECT%20*%20FROM%20public_cases_fc%20WHERE%20requested_datetime%20%3E=%20%272022-01-01%27%20AND%20requested_datetime%20%3C%20%272023-01-01%27') %>%
filter(service_name %in% call311_codes_set,
lat > -1) %>%
dplyr::select(lat, lon) %>%
na.omit() %>%
st_as_sf(coords = c("lon", "lat"), crs = 4326, agr = "constant") %>%
st_transform('ESRI:102729')
# Counts of crime per buffer of house sale
to_train$crimes.Buffer <- to_train %>%
st_buffer(660) %>%
aggregate(mutate(philadelphiCrimes.sf, counter = 1),., sum) %>%
pull(counter)
## Nearest Neighbor Feature
to_train <-
to_train %>%
mutate(
crime_nn1 = nn_function(st_coordinates(to_train),
st_coordinates(philadelphiCrimes.sf), k = 1),
crime_nn2 = nn_function(st_coordinates(to_train),
st_coordinates(philadelphiCrimes.sf), k = 2),
crime_nn3 = nn_function(st_coordinates(to_train),
st_coordinates(philadelphiCrimes.sf), k = 3),
crime_nn4 = nn_function(st_coordinates(to_train),
st_coordinates(philadelphiCrimes.sf), k = 4),
crime_nn5 = nn_function(st_coordinates(to_train),
st_coordinates(philadelphiCrimes.sf), k = 5))
## Plot assault density
ggplot() + geom_sf(data = acsTractsPHL.2020, fill = "grey40") +
stat_density2d(data = data.frame(st_coordinates(philadelphiCrimes.sf)),
aes(X, Y, fill = ..level.., alpha = ..level..),
size = 0.01, bins = 40, geom = 'polygon') +
scale_fill_gradient(low = "#25CB10", high = "#FA7800", name = "Density") +
scale_alpha(range = c(0.00, 0.35), guide = "none") +
labs(title = "Density of WA, PHL") +
mapTheme()
# Counts of 311 per buffer of house sale
to_train$philly311.Buffer <- to_train %>%
st_buffer(660) %>%
aggregate(mutate(philadelphia311.sf, counter = 1),., sum) %>%
pull(counter)
## Nearest Neighbor Feature
to_train <-
to_train %>%
mutate(
p311_nn1 = nn_function(st_coordinates(to_train),
st_coordinates(philadelphia311.sf), k = 1),
p311_nn2 = nn_function(st_coordinates(to_train),
st_coordinates(philadelphia311.sf), k = 2),
p311_nn3 = nn_function(st_coordinates(to_train),
st_coordinates(philadelphia311.sf), k = 3),
p311_nn4 = nn_function(st_coordinates(to_train),
st_coordinates(philadelphia311.sf), k = 4),
p311_nn5 = nn_function(st_coordinates(to_train),
st_coordinates(philadelphia311.sf), k = 5))
## Plot 311 density-????
ggplot() + geom_sf(data = acsTractsPHL.2020, fill = "grey40") +
stat_density2d(data = data.frame(st_coordinates(philadelphia311.sf)),
aes(X, Y, fill = ..level.., alpha = ..level..),
size = 0.01, bins = 40, geom = 'polygon') +
scale_fill_gradient(low = "#25CB10", high = "#FA7800", name = "Density") +
scale_alpha(range = c(0.1, 0.35), guide = "none") +
labs(title = "Density of 311, PHL") +
mapTheme()
landmark <- st_read('https://opendataphilly.org/datasets/city-landmarks/')
landmark <-  read.socrata('https://opendataphilly.org/datasets/city-landmarks/')
school <- st_read('https://raw.githubusercontent.com/azavea/opendataphilly-jkan/main/_datasets/city-landmarks.md')
school <- readLines('https://raw.githubusercontent.com/azavea/opendataphilly-jkan/main/_datasets/city-landmarks.md')
plot(school)
school <- readLines('https://raw.githubusercontent.com/azavea/opendataphilly-jkan/main/_datasets/city-landmarks.md')
school.sf <- school %>%
select(geometry) %>%
na.omit() %>%
distinct()
# Load required packages
install.packages("httr")
library(httr)
# Fetch the content from the URL
url <- "https://raw.githubusercontent.com/azavea/opendataphilly-jkan/main/_datasets/city-landmarks.md"
response <- GET(url)
md_content <- content(response, "text")
# Print the content
cat(md_content, sep = "\n")
install.packages("httr")
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(tidycensus)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(broom)
library(tufte)
library(rmarkdown)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
# functions and data directory
root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
# Load required packages
install.packages("httr")
library(httr)
# Fetch the content from the URL
url <- "https://raw.githubusercontent.com/azavea/opendataphilly-jkan/main/_datasets/city-landmarks.md"
response <- GET(url)
md_content <- content(response, "text")
# Print the content
cat(md_content, sep = "\n")
install.packages("httr")
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(tidycensus)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(broom)
library(tufte)
library(rmarkdown)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
# functions and data directory
root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
url <- "https://raw.githubusercontent.com/azavea/opendataphilly-jkan/main/_datasets/city-landmarks.md"
response <- GET(url)
install.packages("httr")
library(httr)
install.packages("httr")
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(tidycensus)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(broom)
library(tufte)
library(rmarkdown)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
# functions and data directory
root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
url <- "https://raw.githubusercontent.com/azavea/opendataphilly-jkan/main/_datasets/city-landmarks.md"
response <- GET(url)
>>>>>>> Stashed changes
